{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.2.4\n",
      "/home/ec2-user/SageMaker\r\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import tarfile\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D, Lambda\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model, model_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from cv2 import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50\n",
    "from keras import regularizers\n",
    "import requests\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Keras version:', keras.__version__)\n",
    "# print(os.listdir('SageMaker'))\n",
    "\n",
    "warnings.simplefilter('default')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4130318\n",
      "112821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(117703, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './data/landmarks/train/train/'\n",
    "test_path = './data/landmarks/test/test/'\n",
    "train_images = glob.glob(train_path+'*.jpg')\n",
    "test_images = glob.glob(test_path+'*.jpg')\n",
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "sample_submission = pd.read_csv('./data/landmarks/recognition_sample_submission.csv')\n",
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(train_path, '') for image_file in train_images]\n",
    "\n",
    "train_df = pd.DataFrame(index=list(range(0,len(train_image_ids))))\n",
    "train_df['filename'] = pd.Series(train_images, index=list(range(0,len(train_image_ids))))\n",
    "train_df['ids'] = train_image_ids\n",
    "test_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(test_path, '') for image_file in test_images]\n",
    "test_df = pd.DataFrame(index=list(range(0,len(test_image_ids))))\n",
    "test_df['filename'] = pd.Series(test_images, index=list(range(0,len(test_image_ids))))\n",
    "test_df['ids'] = test_image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                url  \\\n",
      "id                                                                    \n",
      "6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
      "3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n",
      "e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "\n",
      "                  landmark_id  \n",
      "id                             \n",
      "6e158a47eb2ca3f6       142820  \n",
      "202cd79556f30760       104169  \n",
      "3ad87684c99c06e1        37914  \n",
      "e7f70e9c61e66af3       102140  \n",
      "4072182eddd0100e         2474  \n",
      "(4132914, 2)\n",
      "Number of classes 203094\n",
      "Total number of valid classes: 23215\n",
      "url            0\n",
      "landmark_id    0\n",
      "filename       0\n",
      "dtype: int64\n",
      "Total number of valid examples: 2296997\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\",index_col='id')\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(\"Number of classes {}\".format(len(train.landmark_id.unique())))\n",
    "\n",
    "NUM_THRESHOLD = 42\n",
    "\n",
    "counts = dict(Counter(train['landmark_id']))\n",
    "landmarks_dict = {x:[] for x in train.landmark_id.unique() if counts[x] >= NUM_THRESHOLD}\n",
    "NUM_CLASSES = len(landmarks_dict)\n",
    "print(\"Total number of valid classes: {}\".format(NUM_CLASSES))\n",
    "\n",
    "i = 0\n",
    "landmark_to_idx = {}\n",
    "idx_to_landmark = []\n",
    "for k in landmarks_dict:\n",
    "    landmark_to_idx[k] = i\n",
    "    idx_to_landmark.append(k)\n",
    "    i += 1\n",
    "    \n",
    "train['filename'] = pd.Series(train_images, index=train_image_ids)\n",
    "\n",
    "train = train.dropna(axis=0)\n",
    "print(train.isna().sum())\n",
    "\n",
    "all_urls = train['url'].tolist()\n",
    "all_filenames= train['filename'].tolist()\n",
    "all_landmarks = train['landmark_id'].tolist()\n",
    "valid_urls_dict = {x[0].split(\"/\")[-1]:landmark_to_idx[x[1]] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict}\n",
    "valid_filenames_dict = {x[0].split('/')[-1]:landmark_to_idx[x[1]] for x in zip(all_filenames, all_landmarks) if x[1] in landmarks_dict}\n",
    "valid_urls_list = [x[0] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict]\n",
    "valid_filenames_list = [x[0] for x in zip(all_filenames, all_landmarks) if x[1] in landmarks_dict]\n",
    "\n",
    "NUM_EXAMPLES = len(valid_urls_list)\n",
    "print(\"Total number of valid examples: {}\".format(NUM_EXAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fa8d5a81a16f2f2f</th>\n",
       "      <td>https://lh3.googleusercontent.com/-_SAJTBt3Y64...</td>\n",
       "      <td>./data/landmarks/test/test/fa8d5a81a16f2f2f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b81a0a45f9b1ee97</th>\n",
       "      <td>https://lh3.googleusercontent.com/-9sFSIOCzIOs...</td>\n",
       "      <td>./data/landmarks/test/test/b81a0a45f9b1ee97.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570e28cc63fab858</th>\n",
       "      <td>https://lh3.googleusercontent.com/-7Eld7yUfAB0...</td>\n",
       "      <td>./data/landmarks/test/test/570e28cc63fab858.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8bc63608b5fef1a</th>\n",
       "      <td>https://lh3.googleusercontent.com/-JdgzGjeS9NE...</td>\n",
       "      <td>./data/landmarks/test/test/b8bc63608b5fef1a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54cfd1f5f683b966</th>\n",
       "      <td>https://lh3.googleusercontent.com/-krCM7YZ3FpU...</td>\n",
       "      <td>./data/landmarks/test/test/54cfd1f5f683b966.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                url  \\\n",
       "id                                                                    \n",
       "fa8d5a81a16f2f2f  https://lh3.googleusercontent.com/-_SAJTBt3Y64...   \n",
       "b81a0a45f9b1ee97  https://lh3.googleusercontent.com/-9sFSIOCzIOs...   \n",
       "570e28cc63fab858  https://lh3.googleusercontent.com/-7Eld7yUfAB0...   \n",
       "b8bc63608b5fef1a  https://lh3.googleusercontent.com/-JdgzGjeS9NE...   \n",
       "54cfd1f5f683b966  https://lh3.googleusercontent.com/-krCM7YZ3FpU...   \n",
       "\n",
       "                                                         filename  \n",
       "id                                                                 \n",
       "fa8d5a81a16f2f2f  ./data/landmarks/test/test/fa8d5a81a16f2f2f.jpg  \n",
       "b81a0a45f9b1ee97  ./data/landmarks/test/test/b81a0a45f9b1ee97.jpg  \n",
       "570e28cc63fab858  ./data/landmarks/test/test/570e28cc63fab858.jpg  \n",
       "b8bc63608b5fef1a  ./data/landmarks/test/test/b8bc63608b5fef1a.jpg  \n",
       "54cfd1f5f683b966  ./data/landmarks/test/test/54cfd1f5f683b966.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info_full = pd.read_csv('./data/test.csv', index_col='id')\n",
    "test_info_full.head()\n",
    "\n",
    "test_info = test_info_full.loc[test_image_ids]\n",
    "test_info['filename'] = pd.Series(test_images, index=test_image_ids)\n",
    "\n",
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p0_label</th>\n",
       "      <th>p1_label</th>\n",
       "      <th>p1_landmark</th>\n",
       "      <th>p2_label</th>\n",
       "      <th>p2_landmark</th>\n",
       "      <th>landmark_file</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p0_landmark</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-landmark</th>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>236</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>/a/archive</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>687c09f942938f4e.jpg</td>\n",
       "      <td>198059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landmark</th>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>309</td>\n",
       "      <td>76</td>\n",
       "      <td>234</td>\n",
       "      <td>/s/snowfield</td>\n",
       "      <td>/c/campsite</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/m/mountain_snowy</td>\n",
       "      <td>landmark</td>\n",
       "      <td>11704d4b86f8fe1a.jpg</td>\n",
       "      <td>136542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-landmark</th>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>93</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "      <td>/c/clean_room</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>67e34bedf25bd3d2.jpg</td>\n",
       "      <td>180256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landmark</th>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>/i/iceberg</td>\n",
       "      <td>/i/ice_shelf</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_floe</td>\n",
       "      <td>landmark</td>\n",
       "      <td>05250fb79c967abb.jpg</td>\n",
       "      <td>151989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landmark</th>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>296</td>\n",
       "      <td>183</td>\n",
       "      <td>107</td>\n",
       "      <td>/s/schoolhouse</td>\n",
       "      <td>/h/house</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/cottage</td>\n",
       "      <td>landmark</td>\n",
       "      <td>ceb9fde5122403d6.jpg</td>\n",
       "      <td>151069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  filename   p0   p1   p2  \\\n",
       "p0_landmark                                                                 \n",
       "non-landmark  ./landmarks/train/train/687c09f942938f4e.jpg  236   14  240   \n",
       "landmark      ./landmarks/train/train/11704d4b86f8fe1a.jpg  309   76  234   \n",
       "non-landmark  ./landmarks/train/train/67e34bedf25bd3d2.jpg   93  236  240   \n",
       "landmark      ./landmarks/train/train/05250fb79c967abb.jpg  190  187  186   \n",
       "landmark      ./landmarks/train/train/ceb9fde5122403d6.jpg  296  183  107   \n",
       "\n",
       "                      p0_label          p1_label   p1_landmark  \\\n",
       "p0_landmark                                                      \n",
       "non-landmark  /m/museum/indoor        /a/archive  non-landmark   \n",
       "landmark          /s/snowfield       /c/campsite      landmark   \n",
       "non-landmark     /c/clean_room  /m/museum/indoor  non-landmark   \n",
       "landmark            /i/iceberg      /i/ice_shelf      landmark   \n",
       "landmark        /s/schoolhouse          /h/house      landmark   \n",
       "\n",
       "                       p2_label   p2_landmark         landmark_file  \\\n",
       "p0_landmark                                                           \n",
       "non-landmark         /n/nursery  non-landmark  687c09f942938f4e.jpg   \n",
       "landmark      /m/mountain_snowy      landmark  11704d4b86f8fe1a.jpg   \n",
       "non-landmark         /n/nursery  non-landmark  67e34bedf25bd3d2.jpg   \n",
       "landmark            /i/ice_floe      landmark  05250fb79c967abb.jpg   \n",
       "landmark             /c/cottage      landmark  ceb9fde5122403d6.jpg   \n",
       "\n",
       "              landmark_id  \n",
       "p0_landmark                \n",
       "non-landmark       198059  \n",
       "landmark           136542  \n",
       "non-landmark       180256  \n",
       "landmark           151989  \n",
       "landmark           151069  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_subsample = pd.read_csv('./data/topn_all_info.csv',index_col=['p0_landmark'])\n",
    "landmark_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0_landmark</th>\n",
       "      <th>filename</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>landmark</td>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>136542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>landmark</td>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>151989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>landmark</td>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>151069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>landmark</td>\n",
       "      <td>./landmarks/train/train/ea63b03baf3073fa.jpg</td>\n",
       "      <td>64858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>landmark</td>\n",
       "      <td>./landmarks/train/train/6ebaaa17fd934ab5.jpg</td>\n",
       "      <td>179389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p0_landmark                                      filename  landmark_id\n",
       "0    landmark  ./landmarks/train/train/11704d4b86f8fe1a.jpg       136542\n",
       "1    landmark  ./landmarks/train/train/05250fb79c967abb.jpg       151989\n",
       "2    landmark  ./landmarks/train/train/ceb9fde5122403d6.jpg       151069\n",
       "3    landmark  ./landmarks/train/train/ea63b03baf3073fa.jpg        64858\n",
       "4    landmark  ./landmarks/train/train/6ebaaa17fd934ab5.jpg       179389"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_landmark = pd.read_csv('./data/confirmed_landmarks.csv')\n",
    "is_landmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0_landmark</th>\n",
       "      <th>filename</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-landmark</td>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>198059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-landmark</td>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>180256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-landmark</td>\n",
       "      <td>./landmarks/train/train/a07dd54e2b44e4d9.jpg</td>\n",
       "      <td>142367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-landmark</td>\n",
       "      <td>./landmarks/train/train/a2b9ebee1790da61.jpg</td>\n",
       "      <td>58639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-landmark</td>\n",
       "      <td>./landmarks/train/train/6fbbf834306edd36.jpg</td>\n",
       "      <td>56102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p0_landmark                                      filename  landmark_id\n",
       "0  non-landmark  ./landmarks/train/train/687c09f942938f4e.jpg       198059\n",
       "1  non-landmark  ./landmarks/train/train/67e34bedf25bd3d2.jpg       180256\n",
       "2  non-landmark  ./landmarks/train/train/a07dd54e2b44e4d9.jpg       142367\n",
       "3  non-landmark  ./landmarks/train/train/a2b9ebee1790da61.jpg        58639\n",
       "4  non-landmark  ./landmarks/train/train/6fbbf834306edd36.jpg        56102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_landmark = pd.read_csv('./data/not_landmarks.csv')\n",
    "not_landmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat = 203094 #number of unique classes (yikes)\n",
    "n_valid_classes = 23215\n",
    "input_shape = (99,99)\n",
    "batch_size = 48\n",
    "batch_size_predict = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder(sparse=True, n_values=n_cat)\n",
    "\n",
    "train['label'] = label_encoder.fit_transform(train['landmark_id'].values)\n",
    "train['one_hot'] = one_hot_encoder.fit_transform(\n",
    "                    train['label'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/landmarks/train/train/3ad87684c99c06e1.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['filename'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'resize/Squeeze:0' shape=(99, 99, ?) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.read_file(train['filename'][2])\n",
    "d = tf.image.decode_jpeg(t)\n",
    "r = tf.image.resize(d,[99,99])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf example method\n",
    "# def _read_py_function(filename, label):\n",
    "    \n",
    "#     img = cv2.imread(filename.decode(), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "#     return img, label\n",
    "\n",
    "# # Use standard TensorFlow operations to resize the image to a fixed shape.\n",
    "# def _resize_function(img, label):\n",
    "#     img.set_shape([None, None, None])\n",
    "#     image_resized = tf.image.resize_images(img, [99, 99])\n",
    "#     return image_resized, label\n",
    "\n",
    "# filenames = train['filename'].values\n",
    "# labels = train['landmark_id'].values\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "# dataset = dataset.map(\n",
    "#     lambda filename, label: tuple(tf.py_func(\n",
    "#         _read_py_function, [filename, label], [tf.uint8, label.dtype])))\n",
    "# dataset = dataset.map(_resize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4130318"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#values[ind:(ind+batch_size)]\n",
    "batch_size = 32\n",
    "lmao = []\n",
    "for ind in range(0,len(train),batch_size):\n",
    "    lmao.append('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129073"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lmao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info = train.sample(2000)\n",
    "# batch_size=32\n",
    "# def get_image_gen(info_arg, \n",
    "#                   shuffle=True, \n",
    "#                   image_aug=True, \n",
    "#                   eq_dist=False, \n",
    "#                   n_ref_imgs=16, \n",
    "#                   crop_prob=0.5, \n",
    "#                   crop_p=0.5):\n",
    "#     if image_aug:\n",
    "#         datagen = ImageDataGenerator(\n",
    "#             rotation_range=4.,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2,\n",
    "#             shear_range=0.2,\n",
    "#             zoom_range=0.5,\n",
    "#             channel_shift_range=25,\n",
    "#             horizontal_flip=True,\n",
    "#             fill_mode='nearest')\n",
    "\n",
    "#         if crop_prob > 0:\n",
    "#             datagen_crop = ImageDataGenerator(\n",
    "#                 rotation_range=4.,\n",
    "#                 shear_range=0.2,\n",
    "#                 zoom_range=0.1,\n",
    "#                 channel_shift_range=20,\n",
    "#                 horizontal_flip=True,\n",
    "#                 fill_mode='nearest')\n",
    "            \n",
    "#     while True:\n",
    "#         if eq_dist:\n",
    "#             def sample(df):\n",
    "#                 return df.sample(min(n_ref_imgs, len(df)))\n",
    "#             info = info_arg.groupby('landmark_id', group_keys=False).apply(sample)\n",
    "#         else:\n",
    "#             info = info_arg\n",
    "#         print('Generate', len(info), 'for the next round.')\n",
    "        \n",
    "#         if shuffle and count >= len(info):\n",
    "#             info = info.sample(frac=1)\n",
    "#             count = 0\n",
    "        \n",
    "#         for ind in range(0,len(info),batch_size):\n",
    "#             count+=1\n",
    "#             y = info['landmark_id'].values[ind:(ind+batch_size)]\n",
    "            \n",
    "#             if np.random.rand() < crop_prob:\n",
    "#                 imgs = load_cropped_images(info.iloc[ind:(ind+batch_size)], \n",
    "#                                            crop_p=crop_p*np.random.rand() + 0.01, \n",
    "#                                            crop='random')\n",
    "#                 if image_aug:\n",
    "#                     cflow = datagen_crop.flow(imgs, \n",
    "#                                               y, \n",
    "#                                               batch_size=imgs.shape[0], \n",
    "#                                               shuffle=False)\n",
    "#                     imgs, y = next(cflow)                    \n",
    "#             else:\n",
    "#                 imgs = load_images(info.iloc[ind:(ind+batch_size)])\n",
    "#                 if image_aug:\n",
    "#                     cflow = datagen.flow(imgs, \n",
    "#                                        y, \n",
    "#                                        batch_size=imgs.shape[0], \n",
    "#                                        shuffle=False)\n",
    "#                     imgs, y = next(cflow)             \n",
    "           \n",
    "#                 imgs = preprocess_input(imgs)\n",
    "\n",
    "#                 y_l = label_encoder.transform(y[y>=0.])        \n",
    "#                 y_oh = np.zeros((len(y), n_cat))\n",
    "#                 y_oh[y >= 0., :] = one_hot_encoder.transform(y_l.reshape(-1,1)).todense()\n",
    "\n",
    "#                 yield imgs, y_oh\n",
    "\n",
    "\n",
    "# train_gen = get_image_gen(train, \n",
    "#                           eq_dist=True, \n",
    "#                           n_ref_imgs=512, \n",
    "#                           crop_prob=0.5, \n",
    "#                           crop_p=0.5) \n",
    "# print(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>one_hot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6e158a47eb2ca3f6</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>142820</td>\n",
       "      <td>./data/landmarks/train/train/6e158a47eb2ca3f6.jpg</td>\n",
       "      <td>142820</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202cd79556f30760</th>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>104169</td>\n",
       "      <td>./data/landmarks/train/train/202cd79556f30760.jpg</td>\n",
       "      <td>104169</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ad87684c99c06e1</th>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>37914</td>\n",
       "      <td>./data/landmarks/train/train/3ad87684c99c06e1.jpg</td>\n",
       "      <td>37914</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7f70e9c61e66af3</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>102140</td>\n",
       "      <td>./data/landmarks/train/train/e7f70e9c61e66af3.jpg</td>\n",
       "      <td>102140</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072182eddd0100e</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>2474</td>\n",
       "      <td>./data/landmarks/train/train/4072182eddd0100e.jpg</td>\n",
       "      <td>2474</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                url  \\\n",
       "id                                                                    \n",
       "6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "\n",
       "                  landmark_id  \\\n",
       "id                              \n",
       "6e158a47eb2ca3f6       142820   \n",
       "202cd79556f30760       104169   \n",
       "3ad87684c99c06e1        37914   \n",
       "e7f70e9c61e66af3       102140   \n",
       "4072182eddd0100e         2474   \n",
       "\n",
       "                                                           filename   label  \\\n",
       "id                                                                            \n",
       "6e158a47eb2ca3f6  ./data/landmarks/train/train/6e158a47eb2ca3f6.jpg  142820   \n",
       "202cd79556f30760  ./data/landmarks/train/train/202cd79556f30760.jpg  104169   \n",
       "3ad87684c99c06e1  ./data/landmarks/train/train/3ad87684c99c06e1.jpg   37914   \n",
       "e7f70e9c61e66af3  ./data/landmarks/train/train/e7f70e9c61e66af3.jpg  102140   \n",
       "4072182eddd0100e  ./data/landmarks/train/train/4072182eddd0100e.jpg    2474   \n",
       "\n",
       "                                                            one_hot  \n",
       "id                                                                   \n",
       "6e158a47eb2ca3f6    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "202cd79556f30760    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "3ad87684c99c06e1    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "e7f70e9c61e66af3    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "4072182eddd0100e    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e158a47eb2ca3f6</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>142820</td>\n",
       "      <td>./data/landmarks/train/train/6e158a47eb2ca3f6.jpg</td>\n",
       "      <td>142820</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202cd79556f30760</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>104169</td>\n",
       "      <td>./data/landmarks/train/train/202cd79556f30760.jpg</td>\n",
       "      <td>104169</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ad87684c99c06e1</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>37914</td>\n",
       "      <td>./data/landmarks/train/train/3ad87684c99c06e1.jpg</td>\n",
       "      <td>37914</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f70e9c61e66af3</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>102140</td>\n",
       "      <td>./data/landmarks/train/train/e7f70e9c61e66af3.jpg</td>\n",
       "      <td>102140</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4072182eddd0100e</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>2474</td>\n",
       "      <td>./data/landmarks/train/train/4072182eddd0100e.jpg</td>\n",
       "      <td>2474</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "1  202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "2  3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "3  e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "4  4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "\n",
       "   landmark_id                                           filename   label  \\\n",
       "0       142820  ./data/landmarks/train/train/6e158a47eb2ca3f6.jpg  142820   \n",
       "1       104169  ./data/landmarks/train/train/202cd79556f30760.jpg  104169   \n",
       "2        37914  ./data/landmarks/train/train/3ad87684c99c06e1.jpg   37914   \n",
       "3       102140  ./data/landmarks/train/train/e7f70e9c61e66af3.jpg  102140   \n",
       "4         2474  ./data/landmarks/train/train/4072182eddd0100e.jpg    2474   \n",
       "\n",
       "                                             one_hot  \n",
       "0    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "1    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "2    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "3    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "4    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.reset_index()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(info, input_shape = input_shape):\n",
    "    input_shape = tuple(input_shape)\n",
    "    imgs = np.zeros((len(info), input_shape[0], input_shape[1], 3))\n",
    "\n",
    "    for i in range(len(info)):\n",
    "        fname = info.iloc[i]['filename']\n",
    "        try:\n",
    "            img = cv2.cvtColor(\n",
    "                  cv2.resize(cv2.imread(fname),input_shape),\n",
    "                  cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            warnings.warn('Warning: could not read image: '+ fname +\n",
    "                          '. Use black img instead.')\n",
    "            img = np.zeros((input_shape[0], input_shape[1], 3))\n",
    "        imgs[i,:,:,:] = img\n",
    "    \n",
    "    return imgs\n",
    "def load_cropped_images(info, crop_p=0.2, crop='random'):\n",
    "    new_res = np.array([int(input_shape[0]*(1+crop_p)), int(input_shape[1]*(1+crop_p))])\n",
    "    if crop == 'random':\n",
    "        cx0 = np.random.randint(new_res[0] - input_shape[0], size=len(info))\n",
    "        cy0 = np.random.randint(new_res[1] - input_shape[1], size=len(info))\n",
    "    else:\n",
    "        if crop == 'central':\n",
    "            cx0, cy0 = (new_res - input_shape) // 2                \n",
    "        if crop == 'upper left':\n",
    "            cx0, cy0 = 0, 0\n",
    "        if crop == 'upper right':\n",
    "            cx0, cy0 = new_res[1] - input_shape[1], 0\n",
    "        if crop == 'lower left':\n",
    "            cx0, cy0 = 0, new_res[0] - input_shape[0]\n",
    "        if crop=='lower right':\n",
    "            cx0, cy0 = new_res - input_shape        \n",
    "        cx0 = np.repeat(np.expand_dims(cx0, 0), len(info))\n",
    "        cy0 = np.repeat(np.expand_dims(cy0, 0), len(info))\n",
    "\n",
    "    cx1 = cx0 + input_shape[0]\n",
    "    cy1 = cy0 + input_shape[1]\n",
    "    \n",
    "    raw_imgs = load_images(info, input_shape=tuple(new_res))\n",
    "    \n",
    "    cropped_imgs = np.zeros((len(info), input_shape[0], input_shape[1], 3))\n",
    "    for ind in range(len(info)):\n",
    "        cropped_imgs[ind,:,:,:] = raw_imgs[ind,\n",
    "                                           cy0[ind]:cy1[ind],\n",
    "                                           cx0[ind]:cx1[ind], :]\n",
    "    \n",
    "    return cropped_imgs\n",
    "\n",
    "\n",
    "def get_image_gen(info_arg, \n",
    "                  shuffle=True, \n",
    "                  image_aug=True, \n",
    "                  eq_dist=False, \n",
    "                  n_ref_imgs=16, \n",
    "                  crop_prob=0.5, \n",
    "                  crop_p=0.5):\n",
    "    if image_aug:\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=4.,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.5,\n",
    "            channel_shift_range=25,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        \n",
    "        if crop_prob > 0:\n",
    "            datagen_crop = ImageDataGenerator(\n",
    "                rotation_range=4.,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.1,\n",
    "                channel_shift_range=20,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "        \n",
    "    count = len(info_arg)\n",
    "    while True:\n",
    "        if eq_dist:\n",
    "            def sample(df):\n",
    "                return df.sample(min(n_ref_imgs, len(df)))\n",
    "            info = info_arg.groupby('landmark_id', group_keys=False).apply(sample)\n",
    "        else:\n",
    "            info = info_arg\n",
    "        print('Generate', len(info), 'for the next round.')\n",
    "        \n",
    "        #shuffle data\n",
    "        if shuffle and count >= len(info):\n",
    "            info = info.sample(frac=1)\n",
    "            count = 0\n",
    "            \n",
    "        # load images\n",
    "        for ind in range(0,len(info), batch_size):\n",
    "            count += batch_size\n",
    "\n",
    "            y = info['landmark_id'].values[ind:(ind+batch_size)]\n",
    "            \n",
    "            if np.random.rand() < crop_prob:\n",
    "                imgs = load_cropped_images(info.iloc[ind:(ind+batch_size)], \n",
    "                                           crop_p=crop_p*np.random.rand() + 0.01, \n",
    "                                           crop='random')\n",
    "                if image_aug:\n",
    "                    cflow = datagen_crop.flow(imgs, \n",
    "                                              y, \n",
    "                                              batch_size=imgs.shape[0], \n",
    "                                              shuffle=False)\n",
    "                    imgs, y = next(cflow)                    \n",
    "            else:\n",
    "                imgs = load_images(info.iloc[ind:(ind+batch_size)])\n",
    "                if image_aug:\n",
    "                    cflow = datagen.flow(imgs, \n",
    "                                       y, \n",
    "                                       batch_size=imgs.shape[0], \n",
    "                                       shuffle=False)\n",
    "                    imgs, y = next(cflow)             \n",
    "\n",
    "            imgs = preprocess_input(imgs)\n",
    "    \n",
    "            y_l = label_encoder.transform(y[y>=0.])        \n",
    "            y_oh = np.zeros((len(y), n_cat))\n",
    "            y_oh[y >= 0., :] = one_hot_encoder.transform(y_l.reshape(-1,1)).todense()\n",
    "                    \n",
    "            yield imgs, y_oh\n",
    "            \n",
    "train_gen = get_image_gen(train, \n",
    "                          eq_dist=True, \n",
    "                          n_ref_imgs=512, \n",
    "                          crop_prob=0.3, \n",
    "                          crop_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8b8634e94d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.python.platform import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
