{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.2.4\n",
      "/home/ec2-user/SageMaker\r\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import tarfile\n",
    "import cv2\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D, Lambda\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model, model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from cv2 import resize\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50\n",
    "from keras import regularizers\n",
    "import requests\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import multi_gpu_model\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Keras version:', keras.__version__)\n",
    "# print(os.listdir('SageMaker'))\n",
    "\n",
    "warnings.simplefilter('default')\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay so in this notebook i'm going to put together what i believe will be the 'nonlandmark/islandmark' features\n",
    "\n",
    "## Tbh i should be doing this after i get a score above 0 but fuck it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"./Keras-VGG16-places365/\")\n",
    "from vgg16_places_365 import VGG16_Places365\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4130318\n",
      "112821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(117703, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_cat = 203094\n",
    "# batch_size = 64\n",
    "# batch_size_predict = 128\n",
    "# input_shape = (128,128)\n",
    "\n",
    "train_path = './landmarks/train/train/'\n",
    "test_path = './landmarks/test/test/'\n",
    "train_images = glob.glob(train_path+'*.jpg')\n",
    "test_images = glob.glob(test_path+'*.jpg')\n",
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "sample_submission = pd.read_csv('./landmarks/recognition_sample_submission.csv')\n",
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(train_path, '') for image_file in train_images]\n",
    "\n",
    "train_df = pd.DataFrame(index=list(range(0,len(train_image_ids))))\n",
    "train_df['filename'] = pd.Series(train_images, index=list(range(0,len(train_image_ids))))\n",
    "train_df['ids'] = train_image_ids\n",
    "test_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(test_path, '') for image_file in test_images]\n",
    "test_df = pd.DataFrame(index=list(range(0,len(test_image_ids))))\n",
    "test_df['filename'] = pd.Series(test_images, index=list(range(0,len(test_image_ids))))\n",
    "test_df['ids'] = test_image_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## going to create a cell for all the functions that I got fromthe 19th place solution preprocessing steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_size(url):\n",
    "    r = requests.get(url, stream=True)\n",
    "    return int(r.headers['Content-Length'])\n",
    "\n",
    "def download_file(url, filename, bar=True):\n",
    "    \"\"\"\n",
    "    Helper method handling downloading large files from `url` to `filename`. Returns a pointer to `filename`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chunkSize = 1024\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(filename, 'wb') as f:\n",
    "            if bar:\n",
    "                pbar = tqdm( unit=\"B\", total=int( r.headers['Content-Length'] ) )\n",
    "            for chunk in r.iter_content(chunk_size=chunkSize): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    if bar: \n",
    "                        pbar.update (len(chunk))\n",
    "                    f.write(chunk)\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "def download_image_cv2_urllib(url):\n",
    "    \"\"\"\n",
    "    Modifying the url to download the 360p or 720p version actually slows it down. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = urllib.request.urlopen(url)\n",
    "        foo = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        foo = cv2.imdecode(foo, cv2.IMREAD_COLOR)\n",
    "        foo = cv2.resize(foo,(128, 128), interpolation=cv2.INTER_AREA)\n",
    "        return foo\n",
    "    except:\n",
    "        return np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                url  \\\n",
      "id                                                                    \n",
      "6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
      "3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n",
      "e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "\n",
      "                  landmark_id  \n",
      "id                             \n",
      "6e158a47eb2ca3f6       142820  \n",
      "202cd79556f30760       104169  \n",
      "3ad87684c99c06e1        37914  \n",
      "e7f70e9c61e66af3       102140  \n",
      "4072182eddd0100e         2474  \n",
      "(4132914, 2)\n",
      "Number of classes 203094\n",
      "Total number of valid classes: 339\n",
      "Total number of valid examples: 252356\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\",index_col='id')\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(\"Number of classes {}\".format(len(train.landmark_id.unique())))\n",
    "\n",
    "NUM_THRESHOLD = 420\n",
    "\n",
    "counts = dict(Counter(train['landmark_id']))\n",
    "landmarks_dict = {x:[] for x in train.landmark_id.unique() if counts[x] >= NUM_THRESHOLD}\n",
    "NUM_CLASSES = len(landmarks_dict)\n",
    "print(\"Total number of valid classes: {}\".format(NUM_CLASSES))\n",
    "\n",
    "i = 0\n",
    "landmark_to_idx = {}\n",
    "idx_to_landmark = []\n",
    "for k in landmarks_dict:\n",
    "    landmark_to_idx[k] = i\n",
    "    idx_to_landmark.append(k)\n",
    "    i += 1\n",
    "    \n",
    "train['filename'] = pd.Series(train_images, index=train_image_ids)\n",
    "\n",
    "all_urls = train['url'].tolist()\n",
    "all_landmarks = train['landmark_id'].tolist()\n",
    "valid_urls_dict = {x[0].split(\"/\")[-1]:landmark_to_idx[x[1]] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict}\n",
    "valid_urls_list = [x[0] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict]\n",
    "\n",
    "NUM_EXAMPLES = len(valid_urls_list)\n",
    "print(\"Total number of valid examples: {}\".format(NUM_EXAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fa8d5a81a16f2f2f</th>\n",
       "      <td>https://lh3.googleusercontent.com/-_SAJTBt3Y64...</td>\n",
       "      <td>./landmarks/test/test/fa8d5a81a16f2f2f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b81a0a45f9b1ee97</th>\n",
       "      <td>https://lh3.googleusercontent.com/-9sFSIOCzIOs...</td>\n",
       "      <td>./landmarks/test/test/b81a0a45f9b1ee97.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570e28cc63fab858</th>\n",
       "      <td>https://lh3.googleusercontent.com/-7Eld7yUfAB0...</td>\n",
       "      <td>./landmarks/test/test/570e28cc63fab858.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8bc63608b5fef1a</th>\n",
       "      <td>https://lh3.googleusercontent.com/-JdgzGjeS9NE...</td>\n",
       "      <td>./landmarks/test/test/b8bc63608b5fef1a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54cfd1f5f683b966</th>\n",
       "      <td>https://lh3.googleusercontent.com/-krCM7YZ3FpU...</td>\n",
       "      <td>./landmarks/test/test/54cfd1f5f683b966.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                url  \\\n",
       "id                                                                    \n",
       "fa8d5a81a16f2f2f  https://lh3.googleusercontent.com/-_SAJTBt3Y64...   \n",
       "b81a0a45f9b1ee97  https://lh3.googleusercontent.com/-9sFSIOCzIOs...   \n",
       "570e28cc63fab858  https://lh3.googleusercontent.com/-7Eld7yUfAB0...   \n",
       "b8bc63608b5fef1a  https://lh3.googleusercontent.com/-JdgzGjeS9NE...   \n",
       "54cfd1f5f683b966  https://lh3.googleusercontent.com/-krCM7YZ3FpU...   \n",
       "\n",
       "                                                    filename  \n",
       "id                                                            \n",
       "fa8d5a81a16f2f2f  ./landmarks/test/test/fa8d5a81a16f2f2f.jpg  \n",
       "b81a0a45f9b1ee97  ./landmarks/test/test/b81a0a45f9b1ee97.jpg  \n",
       "570e28cc63fab858  ./landmarks/test/test/570e28cc63fab858.jpg  \n",
       "b8bc63608b5fef1a  ./landmarks/test/test/b8bc63608b5fef1a.jpg  \n",
       "54cfd1f5f683b966  ./landmarks/test/test/54cfd1f5f683b966.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info_full = pd.read_csv('test.csv', index_col='id')\n",
    "test_info_full.head()\n",
    "\n",
    "test_info = test_info_full.loc[test_image_ids]\n",
    "test_info['filename'] = pd.Series(test_images, index=test_image_ids)\n",
    "\n",
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat = 203094 #number of unique classes (yikes)\n",
    "input_shape = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder(sparse=True, n_values=n_cat)\n",
    "\n",
    "train['label'] = label_encoder.fit_transform(train['landmark_id'])\n",
    "train['one_hot'] = one_hot_encoder.fit_transform(\n",
    "                    train['label'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(info, input_shape = input_shape):\n",
    "    input_shape = tuple(input_shape)\n",
    "    imgs = np.zeros((len(info), input_shape[0], input_shape[1], 3))\n",
    "\n",
    "    for i in range(len(info)):\n",
    "        fname = info.iloc[i]['filename']\n",
    "        try:\n",
    "            img = cv2.cvtColor(\n",
    "                  cv2.resize(cv2.imread(fname),input_shape),\n",
    "                  cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            warnings.warn('Warning: could not read image: '+ fname +\n",
    "                          '. Use black img instead.')\n",
    "            img = np.zeros((input_shape[0], input_shape[1], 3))\n",
    "        imgs[i,:,:,:] = img\n",
    "    \n",
    "    return imgs\n",
    "def load_cropped_images(info, crop_p=0.2, crop='random'):\n",
    "    new_res = np.array([int(input_shape[0]*(1+crop_p)), int(input_shape[1]*(1+crop_p))])\n",
    "    if crop == 'random':\n",
    "        cx0 = np.random.randint(new_res[0] - input_shape[0], size=len(info))\n",
    "        cy0 = np.random.randint(new_res[1] - input_shape[1], size=len(info))\n",
    "    else:\n",
    "        if crop == 'central':\n",
    "            cx0, cy0 = (new_res - input_shape) // 2                \n",
    "        if crop == 'upper left':\n",
    "            cx0, cy0 = 0, 0\n",
    "        if crop == 'upper right':\n",
    "            cx0, cy0 = new_res[1] - input_shape[1], 0\n",
    "        if crop == 'lower left':\n",
    "            cx0, cy0 = 0, new_res[0] - input_shape[0]\n",
    "        if crop=='lower right':\n",
    "            cx0, cy0 = new_res - input_shape        \n",
    "        cx0 = np.repeat(np.expand_dims(cx0, 0), len(info))\n",
    "        cy0 = np.repeat(np.expand_dims(cy0, 0), len(info))\n",
    "\n",
    "    cx1 = cx0 + input_shape[0]\n",
    "    cy1 = cy0 + input_shape[1]\n",
    "    \n",
    "    raw_imgs = load_images(info, input_shape=tuple(new_res))\n",
    "    \n",
    "    cropped_imgs = np.zeros((len(info), input_shape[0], input_shape[1], 3))\n",
    "    for ind in range(len(info)):\n",
    "        cropped_imgs[ind,:,:,:] = raw_imgs[ind,\n",
    "                                           cy0[ind]:cy1[ind],\n",
    "                                           cx0[ind]:cx1[ind], :]\n",
    "    \n",
    "    return cropped_imgs\n",
    "\n",
    "\n",
    "def get_image_gen(info_arg, \n",
    "                  shuffle=True, \n",
    "                  image_aug=True, \n",
    "                  eq_dist=False, \n",
    "                  n_ref_imgs=16, \n",
    "                  crop_prob=0.5, \n",
    "                  crop_p=0.5):\n",
    "    if image_aug:\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=4.,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.5,\n",
    "            channel_shift_range=25,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        \n",
    "        if crop_prob > 0:\n",
    "            datagen_crop = ImageDataGenerator(\n",
    "                rotation_range=4.,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.1,\n",
    "                channel_shift_range=20,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "        \n",
    "    count = len(info_arg)\n",
    "    while True:\n",
    "        if eq_dist:\n",
    "            def sample(df):\n",
    "                return df.sample(min(n_ref_imgs, len(df)))\n",
    "            info = info_arg.groupby('landmark_id', group_keys=False).apply(sample)\n",
    "        else:\n",
    "            info = info_arg\n",
    "        print('Generate', len(info), 'for the next round.')\n",
    "        \n",
    "        #shuffle data\n",
    "        if shuffle and count >= len(info):\n",
    "            info = info.sample(frac=1)\n",
    "            count = 0\n",
    "            \n",
    "        # load images\n",
    "        for ind in range(0,len(info), batch_size):\n",
    "            count += batch_size\n",
    "\n",
    "            y = info['landmark_id'].values[ind:(ind+batch_size)]\n",
    "            \n",
    "            if np.random.rand() < crop_prob:\n",
    "                imgs = load_cropped_images(info.iloc[ind:(ind+batch_size)], \n",
    "                                           crop_p=crop_p*np.random.rand() + 0.01, \n",
    "                                           crop='random')\n",
    "                if image_aug:\n",
    "                    cflow = datagen_crop.flow(imgs, \n",
    "                                              y, \n",
    "                                              batch_size=imgs.shape[0], \n",
    "                                              shuffle=False)\n",
    "                    imgs, y = next(cflow)                    \n",
    "            else:\n",
    "                imgs = load_images(info.iloc[ind:(ind+batch_size)])\n",
    "                if image_aug:\n",
    "                    cflow = datagen.flow(imgs, \n",
    "                                       y, \n",
    "                                       batch_size=imgs.shape[0], \n",
    "                                       shuffle=False)\n",
    "                    imgs, y = next(cflow)             \n",
    "\n",
    "            imgs = preprocess_input(imgs)\n",
    "    \n",
    "            y_l = label_encoder.transform(y[y>=0.])        \n",
    "            y_oh = np.zeros((len(y), n_cat))\n",
    "            y_oh[y >= 0., :] = one_hot_encoder.transform(y_l.reshape(-1,1)).todense()\n",
    "                    \n",
    "            yield imgs, y_oh\n",
    "            \n",
    "train_gen = get_image_gen(train, \n",
    "                          eq_dist=False, \n",
    "                          n_ref_imgs=256, \n",
    "                          crop_prob=0.5, \n",
    "                          crop_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203094\n"
     ]
    }
   ],
   "source": [
    "n_cat_train=train['landmark_id'].nunique()\n",
    "print(n_cat_train)\n",
    "if n_cat_train != n_cat:\n",
    "    warnings.warn('Warning: The training data is not compatible.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = pd.read_csv('topn_all_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks['landmark_file'] = [image_file.replace(\n",
    "    './landmarks/train/train/', '').replace(image_file, '') for image_file in landmarks['filename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks['landmark_id'] = [image_file.replace(\n",
    "    '.jpg', '').replace(image_file, '') for image_file in landmarks['landmark_file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p0_label</th>\n",
       "      <th>p0_landmark</th>\n",
       "      <th>p1_label</th>\n",
       "      <th>p1_landmark</th>\n",
       "      <th>p2_label</th>\n",
       "      <th>p2_landmark</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>landmark_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>236</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/a/archive</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>687c09f942938f4e</td>\n",
       "      <td>687c09f942938f4e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>309</td>\n",
       "      <td>76</td>\n",
       "      <td>234</td>\n",
       "      <td>/s/snowfield</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/campsite</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/m/mountain_snowy</td>\n",
       "      <td>landmark</td>\n",
       "      <td>11704d4b86f8fe1a</td>\n",
       "      <td>11704d4b86f8fe1a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>93</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "      <td>/c/clean_room</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>67e34bedf25bd3d2</td>\n",
       "      <td>67e34bedf25bd3d2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>/i/iceberg</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_shelf</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_floe</td>\n",
       "      <td>landmark</td>\n",
       "      <td>05250fb79c967abb</td>\n",
       "      <td>05250fb79c967abb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>296</td>\n",
       "      <td>183</td>\n",
       "      <td>107</td>\n",
       "      <td>/s/schoolhouse</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/h/house</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/cottage</td>\n",
       "      <td>landmark</td>\n",
       "      <td>ceb9fde5122403d6</td>\n",
       "      <td>ceb9fde5122403d6.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename   p0   p1   p2  \\\n",
       "0  ./landmarks/train/train/687c09f942938f4e.jpg  236   14  240   \n",
       "1  ./landmarks/train/train/11704d4b86f8fe1a.jpg  309   76  234   \n",
       "2  ./landmarks/train/train/67e34bedf25bd3d2.jpg   93  236  240   \n",
       "3  ./landmarks/train/train/05250fb79c967abb.jpg  190  187  186   \n",
       "4  ./landmarks/train/train/ceb9fde5122403d6.jpg  296  183  107   \n",
       "\n",
       "           p0_label   p0_landmark          p1_label   p1_landmark  \\\n",
       "0  /m/museum/indoor  non-landmark        /a/archive  non-landmark   \n",
       "1      /s/snowfield      landmark       /c/campsite      landmark   \n",
       "2     /c/clean_room  non-landmark  /m/museum/indoor  non-landmark   \n",
       "3        /i/iceberg      landmark      /i/ice_shelf      landmark   \n",
       "4    /s/schoolhouse      landmark          /h/house      landmark   \n",
       "\n",
       "            p2_label   p2_landmark       landmark_id         landmark_file  \n",
       "0         /n/nursery  non-landmark  687c09f942938f4e  687c09f942938f4e.jpg  \n",
       "1  /m/mountain_snowy      landmark  11704d4b86f8fe1a  11704d4b86f8fe1a.jpg  \n",
       "2         /n/nursery  non-landmark  67e34bedf25bd3d2  67e34bedf25bd3d2.jpg  \n",
       "3        /i/ice_floe      landmark  05250fb79c967abb  05250fb79c967abb.jpg  \n",
       "4         /c/cottage      landmark  ceb9fde5122403d6  ceb9fde5122403d6.jpg  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks.set_index('landmark_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.set_index('landmark_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6e158a47eb2ca3f6</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>142820</td>\n",
       "      <td>./landmarks/train/train/6e158a47eb2ca3f6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202cd79556f30760</th>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>104169</td>\n",
       "      <td>./landmarks/train/train/202cd79556f30760.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ad87684c99c06e1</th>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>37914</td>\n",
       "      <td>./landmarks/train/train/3ad87684c99c06e1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7f70e9c61e66af3</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>102140</td>\n",
       "      <td>./landmarks/train/train/e7f70e9c61e66af3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072182eddd0100e</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>2474</td>\n",
       "      <td>./landmarks/train/train/4072182eddd0100e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                url  \\\n",
       "id                                                                    \n",
       "6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "\n",
       "                  landmark_id                                      filename  \n",
       "id                                                                           \n",
       "6e158a47eb2ca3f6       142820  ./landmarks/train/train/6e158a47eb2ca3f6.jpg  \n",
       "202cd79556f30760       104169  ./landmarks/train/train/202cd79556f30760.jpg  \n",
       "3ad87684c99c06e1        37914  ./landmarks/train/train/3ad87684c99c06e1.jpg  \n",
       "e7f70e9c61e66af3       102140  ./landmarks/train/train/e7f70e9c61e66af3.jpg  \n",
       "4072182eddd0100e         2474  ./landmarks/train/train/4072182eddd0100e.jpg  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = landmarks.index\n",
    "landmark_ids = []\n",
    "for ids in index:\n",
    "    if ids in train.index:\n",
    "        landmark_ids.append(train['landmark_id'].loc[ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks['landmark_id'] = landmark_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p0_label</th>\n",
       "      <th>p0_landmark</th>\n",
       "      <th>p1_label</th>\n",
       "      <th>p1_landmark</th>\n",
       "      <th>p2_label</th>\n",
       "      <th>p2_landmark</th>\n",
       "      <th>landmark_file</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landmark_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>687c09f942938f4e</th>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>236</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/a/archive</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>687c09f942938f4e.jpg</td>\n",
       "      <td>198059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11704d4b86f8fe1a</th>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>309</td>\n",
       "      <td>76</td>\n",
       "      <td>234</td>\n",
       "      <td>/s/snowfield</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/campsite</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/m/mountain_snowy</td>\n",
       "      <td>landmark</td>\n",
       "      <td>11704d4b86f8fe1a.jpg</td>\n",
       "      <td>136542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67e34bedf25bd3d2</th>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>93</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "      <td>/c/clean_room</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>67e34bedf25bd3d2.jpg</td>\n",
       "      <td>180256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05250fb79c967abb</th>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>/i/iceberg</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_shelf</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_floe</td>\n",
       "      <td>landmark</td>\n",
       "      <td>05250fb79c967abb.jpg</td>\n",
       "      <td>151989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceb9fde5122403d6</th>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>296</td>\n",
       "      <td>183</td>\n",
       "      <td>107</td>\n",
       "      <td>/s/schoolhouse</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/h/house</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/cottage</td>\n",
       "      <td>landmark</td>\n",
       "      <td>ceb9fde5122403d6.jpg</td>\n",
       "      <td>151069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      filename   p0   p1   p2  \\\n",
       "landmark_id                                                                     \n",
       "687c09f942938f4e  ./landmarks/train/train/687c09f942938f4e.jpg  236   14  240   \n",
       "11704d4b86f8fe1a  ./landmarks/train/train/11704d4b86f8fe1a.jpg  309   76  234   \n",
       "67e34bedf25bd3d2  ./landmarks/train/train/67e34bedf25bd3d2.jpg   93  236  240   \n",
       "05250fb79c967abb  ./landmarks/train/train/05250fb79c967abb.jpg  190  187  186   \n",
       "ceb9fde5122403d6  ./landmarks/train/train/ceb9fde5122403d6.jpg  296  183  107   \n",
       "\n",
       "                          p0_label   p0_landmark          p1_label  \\\n",
       "landmark_id                                                          \n",
       "687c09f942938f4e  /m/museum/indoor  non-landmark        /a/archive   \n",
       "11704d4b86f8fe1a      /s/snowfield      landmark       /c/campsite   \n",
       "67e34bedf25bd3d2     /c/clean_room  non-landmark  /m/museum/indoor   \n",
       "05250fb79c967abb        /i/iceberg      landmark      /i/ice_shelf   \n",
       "ceb9fde5122403d6    /s/schoolhouse      landmark          /h/house   \n",
       "\n",
       "                   p1_landmark           p2_label   p2_landmark  \\\n",
       "landmark_id                                                       \n",
       "687c09f942938f4e  non-landmark         /n/nursery  non-landmark   \n",
       "11704d4b86f8fe1a      landmark  /m/mountain_snowy      landmark   \n",
       "67e34bedf25bd3d2  non-landmark         /n/nursery  non-landmark   \n",
       "05250fb79c967abb      landmark        /i/ice_floe      landmark   \n",
       "ceb9fde5122403d6      landmark         /c/cottage      landmark   \n",
       "\n",
       "                         landmark_file  landmark_id  \n",
       "landmark_id                                          \n",
       "687c09f942938f4e  687c09f942938f4e.jpg       198059  \n",
       "11704d4b86f8fe1a  11704d4b86f8fe1a.jpg       136542  \n",
       "67e34bedf25bd3d2  67e34bedf25bd3d2.jpg       180256  \n",
       "05250fb79c967abb  05250fb79c967abb.jpg       151989  \n",
       "ceb9fde5122403d6  ceb9fde5122403d6.jpg       151069  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks.to_csv('topn_all_info.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61993, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset 15% of the training set\n",
    "train_sample = train.sample(n=61993,random_state=42)\n",
    "train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url             0\n",
       "landmark_id     0\n",
       "filename       52\n",
       "label           0\n",
       "one_hot         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url            0\n",
       "landmark_id    0\n",
       "filename       0\n",
       "label          0\n",
       "one_hot        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train_sample.dropna(axis=0)\n",
    "train_sample.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>one_hot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>687c09f942938f4e</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>198059</td>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>198059</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11704d4b86f8fe1a</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>136542</td>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>136542</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67e34bedf25bd3d2</th>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>180256</td>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>180256</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05250fb79c967abb</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>151989</td>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>151989</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceb9fde5122403d6</th>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>151069</td>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>151069</td>\n",
       "      <td>(0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                url  \\\n",
       "id                                                                    \n",
       "687c09f942938f4e  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "11704d4b86f8fe1a  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "67e34bedf25bd3d2  http://upload.wikimedia.org/wikipedia/commons/...   \n",
       "05250fb79c967abb  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "ceb9fde5122403d6  https://upload.wikimedia.org/wikipedia/commons...   \n",
       "\n",
       "                  landmark_id                                      filename  \\\n",
       "id                                                                            \n",
       "687c09f942938f4e       198059  ./landmarks/train/train/687c09f942938f4e.jpg   \n",
       "11704d4b86f8fe1a       136542  ./landmarks/train/train/11704d4b86f8fe1a.jpg   \n",
       "67e34bedf25bd3d2       180256  ./landmarks/train/train/67e34bedf25bd3d2.jpg   \n",
       "05250fb79c967abb       151989  ./landmarks/train/train/05250fb79c967abb.jpg   \n",
       "ceb9fde5122403d6       151069  ./landmarks/train/train/ceb9fde5122403d6.jpg   \n",
       "\n",
       "                   label                                            one_hot  \n",
       "id                                                                           \n",
       "687c09f942938f4e  198059    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "11704d4b86f8fe1a  136542    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "67e34bedf25bd3d2  180256    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "05250fb79c967abb  151989    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  \n",
       "ceb9fde5122403d6  151069    (0, 142820)\\t1.0\\n  (1, 104169)\\t1.0\\n  (2, ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sample['filename'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import resize\n",
    "\n",
    "images_for_train = train_sample['filename'].values\n",
    "final_filenames = []\n",
    "all_images_resized = []\n",
    "\n",
    "for filename in images_for_train: \n",
    "#     print(type(filename))\n",
    "    f = Image.open(filename)\n",
    "    im = np.array(f.resize((224, 224), Image.LANCZOS))    \n",
    "    if len(im.shape) == 3:\n",
    "        all_images_resized.append(im)\n",
    "        final_filenames.append(filename)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame(final_filenames,columns=['filenames'])\n",
    "images_df['all_images_resized'] = all_images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61614"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.expand_dims(all_images_resized[2], 0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61614"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_images = []\n",
    "# for i in range(0,len(all_images_resized)):\n",
    "#     x = all_images_resized[i].shape\n",
    "#     if len(x) == 3:\n",
    "#         all_images.append(all_images_resized[i])\n",
    "#     else:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61614"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-78cf8e6acdb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtopn_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtopn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_for_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtopn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mtopn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtopn_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2760\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3121\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "p0, p1, p2 = [], [], []\n",
    "\n",
    "# Places365 Model\n",
    "model = VGG16_Places365(weights='places')\n",
    "topn = 5\n",
    "\n",
    "# Loop through all images\n",
    "for image in all_images:\n",
    "    \n",
    "    # Predict Top N Image Classes\n",
    "    expand_image = np.expand_dims(image, 0)\n",
    "    topn_preds = np.argsort(model.predict(expand_image)[0])[::-1][0:topn]\n",
    "    p0.append(topn_preds[0])\n",
    "    p1.append(topn_preds[1])\n",
    "    p2.append(topn_preds[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>236</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>309</td>\n",
       "      <td>76</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>93</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>296</td>\n",
       "      <td>183</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename   p0   p1   p2\n",
       "0  ./landmarks/train/train/687c09f942938f4e.jpg  236   14  240\n",
       "1  ./landmarks/train/train/11704d4b86f8fe1a.jpg  309   76  234\n",
       "2  ./landmarks/train/train/67e34bedf25bd3d2.jpg   93  236  240\n",
       "3  ./landmarks/train/train/05250fb79c967abb.jpg  190  187  186\n",
       "4  ./landmarks/train/train/ceb9fde5122403d6.jpg  296  183  107"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for later usage\n",
    "topn_df = pd.DataFrame()\n",
    "topn_df['filename'] = np.array(images_df['filenames'])\n",
    "topn_df['p0'] = np.array(p0)\n",
    "topn_df['p1'] = np.array(p1)\n",
    "topn_df['p2'] = np.array(p2)\n",
    "topn_df.to_csv('topn_class_numbers.csv', index = False)\n",
    "\n",
    "# Summary\n",
    "topn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 label  class  io\n",
      "0          /a/airfield      0   2\n",
      "1    /a/airplane_cabin      1   1\n",
      "2  /a/airport_terminal      2   1\n",
      "3            /a/alcove      3   1\n",
      "4             /a/alley      4   2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p0_label</th>\n",
       "      <th>p0_landmark</th>\n",
       "      <th>p1_label</th>\n",
       "      <th>p1_landmark</th>\n",
       "      <th>p2_label</th>\n",
       "      <th>p2_landmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>236</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/a/archive</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>309</td>\n",
       "      <td>76</td>\n",
       "      <td>234</td>\n",
       "      <td>/s/snowfield</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/campsite</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/m/mountain_snowy</td>\n",
       "      <td>landmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>93</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "      <td>/c/clean_room</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>/i/iceberg</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_shelf</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_floe</td>\n",
       "      <td>landmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>296</td>\n",
       "      <td>183</td>\n",
       "      <td>107</td>\n",
       "      <td>/s/schoolhouse</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/h/house</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/cottage</td>\n",
       "      <td>landmark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       filename   p0   p1   p2  \\\n",
       "0  ./landmarks/train/train/687c09f942938f4e.jpg  236   14  240   \n",
       "1  ./landmarks/train/train/11704d4b86f8fe1a.jpg  309   76  234   \n",
       "2  ./landmarks/train/train/67e34bedf25bd3d2.jpg   93  236  240   \n",
       "3  ./landmarks/train/train/05250fb79c967abb.jpg  190  187  186   \n",
       "4  ./landmarks/train/train/ceb9fde5122403d6.jpg  296  183  107   \n",
       "\n",
       "           p0_label   p0_landmark          p1_label   p1_landmark  \\\n",
       "0  /m/museum/indoor  non-landmark        /a/archive  non-landmark   \n",
       "1      /s/snowfield      landmark       /c/campsite      landmark   \n",
       "2     /c/clean_room  non-landmark  /m/museum/indoor  non-landmark   \n",
       "3        /i/iceberg      landmark      /i/ice_shelf      landmark   \n",
       "4    /s/schoolhouse      landmark          /h/house      landmark   \n",
       "\n",
       "            p2_label   p2_landmark  \n",
       "0         /n/nursery  non-landmark  \n",
       "1  /m/mountain_snowy      landmark  \n",
       "2         /n/nursery  non-landmark  \n",
       "3        /i/ice_floe      landmark  \n",
       "4         /c/cottage      landmark  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_information = pd.read_csv('./Keras-VGG16-places365/categories_places365_extended.csv')\n",
    "print(class_information.head())\n",
    "\n",
    "# Set Class Labels\n",
    "for col in ['p0', 'p1', 'p2']:\n",
    "    topn_df[col + '_label'] = topn_df[col].map(class_information.set_index('class')['label'])\n",
    "    topn_df[col + '_landmark'] = topn_df[col].map(class_information.set_index('class')['io'].replace({1:'non-landmark', 2:'landmark'}))\n",
    "topn_df.to_csv('topn_all_info.csv', index = False)\n",
    "\n",
    "# Summary\n",
    "topn_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
