{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.2.4\n",
      "/home/ec2-user/SageMaker\r\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import tarfile\n",
    "import cv2\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D\n",
    "from keras.layers import GlobalAveragePooling2D, Lambda\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model, model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from cv2 import resize\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50\n",
    "from keras import regularizers\n",
    "import requests\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import multi_gpu_model\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Keras version:', keras.__version__)\n",
    "# print(os.listdir('SageMaker'))\n",
    "\n",
    "warnings.simplefilter('default')\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4130318\n",
      "112821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(117703, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_cat = 203094\n",
    "# batch_size = 64\n",
    "# batch_size_predict = 128\n",
    "# input_shape = (128,128)\n",
    "\n",
    "train_path = './landmarks/train/train/'\n",
    "test_path = './landmarks/test/test/'\n",
    "train_images = glob.glob(train_path+'*.jpg')\n",
    "test_images = glob.glob(test_path+'*.jpg')\n",
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "sample_submission = pd.read_csv('./landmarks/recognition_sample_submission.csv')\n",
    "sample_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(train_path, '') for image_file in train_images]\n",
    "\n",
    "train_df = pd.DataFrame(index=list(range(0,len(train_image_ids))))\n",
    "train_df['filename'] = pd.Series(train_images, index=list(range(0,len(train_image_ids))))\n",
    "train_df['ids'] = train_image_ids\n",
    "test_image_ids = [image_file.replace(\n",
    "    '.jpg', '').replace(test_path, '') for image_file in test_images]\n",
    "test_df = pd.DataFrame(index=list(range(0,len(test_image_ids))))\n",
    "test_df['filename'] = pd.Series(test_images, index=list(range(0,len(test_image_ids))))\n",
    "test_df['ids'] = test_image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_size(url):\n",
    "    r = requests.get(url, stream=True)\n",
    "    return int(r.headers['Content-Length'])\n",
    "\n",
    "def download_file(url, filename, bar=True):\n",
    "    \"\"\"\n",
    "    Helper method handling downloading large files from `url` to `filename`. Returns a pointer to `filename`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chunkSize = 1024\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(filename, 'wb') as f:\n",
    "            if bar:\n",
    "                pbar = tqdm( unit=\"B\", total=int( r.headers['Content-Length'] ) )\n",
    "            for chunk in r.iter_content(chunk_size=chunkSize): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    if bar: \n",
    "                        pbar.update (len(chunk))\n",
    "                    f.write(chunk)\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    \n",
    "def download_image_cv2_urllib(url):\n",
    "    \"\"\"\n",
    "    Modifying the url to download the 360p or 720p version actually slows it down. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = urllib.request.urlopen(url)\n",
    "        foo = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        foo = cv2.imdecode(foo, cv2.IMREAD_COLOR)\n",
    "        foo = cv2.resize(foo,(128, 128), interpolation=cv2.INTER_AREA)\n",
    "        return foo\n",
    "    except:\n",
    "        return np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                url  \\\n",
      "id                                                                    \n",
      "6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n",
      "3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n",
      "e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n",
      "\n",
      "                  landmark_id  \n",
      "id                             \n",
      "6e158a47eb2ca3f6       142820  \n",
      "202cd79556f30760       104169  \n",
      "3ad87684c99c06e1        37914  \n",
      "e7f70e9c61e66af3       102140  \n",
      "4072182eddd0100e         2474  \n",
      "(4132914, 2)\n",
      "Number of classes 203094\n",
      "Total number of valid classes: 339\n",
      "Total number of valid examples: 252356\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\",index_col='id')\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(\"Number of classes {}\".format(len(train.landmark_id.unique())))\n",
    "\n",
    "NUM_THRESHOLD = 420\n",
    "\n",
    "counts = dict(Counter(train['landmark_id']))\n",
    "landmarks_dict = {x:[] for x in train.landmark_id.unique() if counts[x] >= NUM_THRESHOLD}\n",
    "NUM_CLASSES = len(landmarks_dict)\n",
    "print(\"Total number of valid classes: {}\".format(NUM_CLASSES))\n",
    "\n",
    "i = 0\n",
    "landmark_to_idx = {}\n",
    "idx_to_landmark = []\n",
    "for k in landmarks_dict:\n",
    "    landmark_to_idx[k] = i\n",
    "    idx_to_landmark.append(k)\n",
    "    i += 1\n",
    "    \n",
    "train['filename'] = pd.Series(train_images, index=train_image_ids)\n",
    "\n",
    "all_urls = train['url'].tolist()\n",
    "all_landmarks = train['landmark_id'].tolist()\n",
    "valid_urls_dict = {x[0].split(\"/\")[-1]:landmark_to_idx[x[1]] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict}\n",
    "valid_urls_list = [x[0] for x in zip(all_urls, all_landmarks) if x[1] in landmarks_dict]\n",
    "\n",
    "NUM_EXAMPLES = len(valid_urls_list)\n",
    "print(\"Total number of valid examples: {}\".format(NUM_EXAMPLES)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fa8d5a81a16f2f2f</th>\n",
       "      <td>https://lh3.googleusercontent.com/-_SAJTBt3Y64...</td>\n",
       "      <td>./landmarks/test/test/fa8d5a81a16f2f2f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b81a0a45f9b1ee97</th>\n",
       "      <td>https://lh3.googleusercontent.com/-9sFSIOCzIOs...</td>\n",
       "      <td>./landmarks/test/test/b81a0a45f9b1ee97.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570e28cc63fab858</th>\n",
       "      <td>https://lh3.googleusercontent.com/-7Eld7yUfAB0...</td>\n",
       "      <td>./landmarks/test/test/570e28cc63fab858.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8bc63608b5fef1a</th>\n",
       "      <td>https://lh3.googleusercontent.com/-JdgzGjeS9NE...</td>\n",
       "      <td>./landmarks/test/test/b8bc63608b5fef1a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54cfd1f5f683b966</th>\n",
       "      <td>https://lh3.googleusercontent.com/-krCM7YZ3FpU...</td>\n",
       "      <td>./landmarks/test/test/54cfd1f5f683b966.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                url  \\\n",
       "id                                                                    \n",
       "fa8d5a81a16f2f2f  https://lh3.googleusercontent.com/-_SAJTBt3Y64...   \n",
       "b81a0a45f9b1ee97  https://lh3.googleusercontent.com/-9sFSIOCzIOs...   \n",
       "570e28cc63fab858  https://lh3.googleusercontent.com/-7Eld7yUfAB0...   \n",
       "b8bc63608b5fef1a  https://lh3.googleusercontent.com/-JdgzGjeS9NE...   \n",
       "54cfd1f5f683b966  https://lh3.googleusercontent.com/-krCM7YZ3FpU...   \n",
       "\n",
       "                                                    filename  \n",
       "id                                                            \n",
       "fa8d5a81a16f2f2f  ./landmarks/test/test/fa8d5a81a16f2f2f.jpg  \n",
       "b81a0a45f9b1ee97  ./landmarks/test/test/b81a0a45f9b1ee97.jpg  \n",
       "570e28cc63fab858  ./landmarks/test/test/570e28cc63fab858.jpg  \n",
       "b8bc63608b5fef1a  ./landmarks/test/test/b8bc63608b5fef1a.jpg  \n",
       "54cfd1f5f683b966  ./landmarks/test/test/54cfd1f5f683b966.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info_full = pd.read_csv('test.csv', index_col='id')\n",
    "test_info_full.head()\n",
    "\n",
    "test_info = test_info_full.loc[test_image_ids]\n",
    "test_info['filename'] = pd.Series(test_images, index=test_image_ids)\n",
    "\n",
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p0_label</th>\n",
       "      <th>p1_label</th>\n",
       "      <th>p1_landmark</th>\n",
       "      <th>p2_label</th>\n",
       "      <th>p2_landmark</th>\n",
       "      <th>landmark_file</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p0_landmark</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-landmark</th>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>236</td>\n",
       "      <td>14</td>\n",
       "      <td>240</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>/a/archive</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>687c09f942938f4e.jpg</td>\n",
       "      <td>198059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landmark</th>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>309</td>\n",
       "      <td>76</td>\n",
       "      <td>234</td>\n",
       "      <td>/s/snowfield</td>\n",
       "      <td>/c/campsite</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/m/mountain_snowy</td>\n",
       "      <td>landmark</td>\n",
       "      <td>11704d4b86f8fe1a.jpg</td>\n",
       "      <td>136542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-landmark</th>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>93</td>\n",
       "      <td>236</td>\n",
       "      <td>240</td>\n",
       "      <td>/c/clean_room</td>\n",
       "      <td>/m/museum/indoor</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>/n/nursery</td>\n",
       "      <td>non-landmark</td>\n",
       "      <td>67e34bedf25bd3d2.jpg</td>\n",
       "      <td>180256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landmark</th>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>/i/iceberg</td>\n",
       "      <td>/i/ice_shelf</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/i/ice_floe</td>\n",
       "      <td>landmark</td>\n",
       "      <td>05250fb79c967abb.jpg</td>\n",
       "      <td>151989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landmark</th>\n",
       "      <td>./landmarks/train/train/ceb9fde5122403d6.jpg</td>\n",
       "      <td>296</td>\n",
       "      <td>183</td>\n",
       "      <td>107</td>\n",
       "      <td>/s/schoolhouse</td>\n",
       "      <td>/h/house</td>\n",
       "      <td>landmark</td>\n",
       "      <td>/c/cottage</td>\n",
       "      <td>landmark</td>\n",
       "      <td>ceb9fde5122403d6.jpg</td>\n",
       "      <td>151069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  filename   p0   p1   p2  \\\n",
       "p0_landmark                                                                 \n",
       "non-landmark  ./landmarks/train/train/687c09f942938f4e.jpg  236   14  240   \n",
       "landmark      ./landmarks/train/train/11704d4b86f8fe1a.jpg  309   76  234   \n",
       "non-landmark  ./landmarks/train/train/67e34bedf25bd3d2.jpg   93  236  240   \n",
       "landmark      ./landmarks/train/train/05250fb79c967abb.jpg  190  187  186   \n",
       "landmark      ./landmarks/train/train/ceb9fde5122403d6.jpg  296  183  107   \n",
       "\n",
       "                      p0_label          p1_label   p1_landmark  \\\n",
       "p0_landmark                                                      \n",
       "non-landmark  /m/museum/indoor        /a/archive  non-landmark   \n",
       "landmark          /s/snowfield       /c/campsite      landmark   \n",
       "non-landmark     /c/clean_room  /m/museum/indoor  non-landmark   \n",
       "landmark            /i/iceberg      /i/ice_shelf      landmark   \n",
       "landmark        /s/schoolhouse          /h/house      landmark   \n",
       "\n",
       "                       p2_label   p2_landmark         landmark_file  \\\n",
       "p0_landmark                                                           \n",
       "non-landmark         /n/nursery  non-landmark  687c09f942938f4e.jpg   \n",
       "landmark      /m/mountain_snowy      landmark  11704d4b86f8fe1a.jpg   \n",
       "non-landmark         /n/nursery  non-landmark  67e34bedf25bd3d2.jpg   \n",
       "landmark            /i/ice_floe      landmark  05250fb79c967abb.jpg   \n",
       "landmark             /c/cottage      landmark  ceb9fde5122403d6.jpg   \n",
       "\n",
       "              landmark_id  \n",
       "p0_landmark                \n",
       "non-landmark       198059  \n",
       "landmark           136542  \n",
       "non-landmark       180256  \n",
       "landmark           151989  \n",
       "landmark           151069  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_subsample = pd.read_csv('topn_all_info.csv',index_col=['p0_landmark'])\n",
    "landmark_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 256, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(Image.open(train['filename'][1]))\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'JpegImageFile' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8ae592785626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'JpegImageFile' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0_landmark</th>\n",
       "      <th>filename</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>landmark</td>\n",
       "      <td>./landmarks/train/train/11704d4b86f8fe1a.jpg</td>\n",
       "      <td>136542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>landmark</td>\n",
       "      <td>./landmarks/train/train/05250fb79c967abb.jpg</td>\n",
       "      <td>151989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p0_landmark                                      filename  landmark_id\n",
       "0    landmark  ./landmarks/train/train/11704d4b86f8fe1a.jpg       136542\n",
       "1    landmark  ./landmarks/train/train/05250fb79c967abb.jpg       151989"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_confirmed = pd.DataFrame()\n",
    "landmark_confirmed['filename'] = landmark_subsample['filename'].loc['landmark']\n",
    "landmark_confirmed['landmark_id'] = landmark_subsample['landmark_id'].loc['landmark']\n",
    "landmark_confirmed.reset_index(inplace=True)\n",
    "landmark_confirmed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0_landmark</th>\n",
       "      <th>filename</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-landmark</td>\n",
       "      <td>./landmarks/train/train/687c09f942938f4e.jpg</td>\n",
       "      <td>198059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non-landmark</td>\n",
       "      <td>./landmarks/train/train/67e34bedf25bd3d2.jpg</td>\n",
       "      <td>180256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p0_landmark                                      filename  landmark_id\n",
       "0  non-landmark  ./landmarks/train/train/687c09f942938f4e.jpg       198059\n",
       "1  non-landmark  ./landmarks/train/train/67e34bedf25bd3d2.jpg       180256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_landmark = pd.DataFrame()\n",
    "non_landmark['filename'] = landmark_subsample['filename'].loc['non-landmark']\n",
    "non_landmark['landmark_id'] = landmark_subsample['landmark_id'].loc['non-landmark']\n",
    "non_landmark.reset_index(inplace=True)\n",
    "non_landmark.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These two datasets will be my validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat = 203094 #number of unique classes (yikes)\n",
    "input_shape = (128,128)\n",
    "batch_size=48\n",
    "batch_size_predict=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder(sparse=True, n_values=n_cat)\n",
    "\n",
    "train['label'] = label_encoder.fit_transform(train['landmark_id'].values)\n",
    "train['one_hot'] = one_hot_encoder.fit_transform(\n",
    "                    train['label'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(info, input_shape = input_shape):\n",
    "    input_shape = tuple(input_shape)\n",
    "    imgs = np.zeros((len(info), input_shape[0], input_shape[1], 3))\n",
    "\n",
    "    for i in range(len(info)):\n",
    "        fname = info.iloc[i]['filename']\n",
    "        try:\n",
    "            img = cv2.cvtColor(\n",
    "                  cv2.resize(cv2.imread(fname),input_shape),\n",
    "                  cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            warnings.warn('Warning: could not read image: '+ fname +\n",
    "                          '. Use black img instead.')\n",
    "            img = np.zeros((input_shape[0], input_shape[1], 3))\n",
    "        imgs[i,:,:,:] = img\n",
    "    \n",
    "    return imgs\n",
    "def load_cropped_images(info, crop_p=0.2, crop='random'):\n",
    "    new_res = np.array([int(input_shape[0]*(1+crop_p)), int(input_shape[1]*(1+crop_p))])\n",
    "    if crop == 'random':\n",
    "        cx0 = np.random.randint(new_res[0] - input_shape[0], size=len(info))\n",
    "        cy0 = np.random.randint(new_res[1] - input_shape[1], size=len(info))\n",
    "    else:\n",
    "        if crop == 'central':\n",
    "            cx0, cy0 = (new_res - input_shape) // 2                \n",
    "        if crop == 'upper left':\n",
    "            cx0, cy0 = 0, 0\n",
    "        if crop == 'upper right':\n",
    "            cx0, cy0 = new_res[1] - input_shape[1], 0\n",
    "        if crop == 'lower left':\n",
    "            cx0, cy0 = 0, new_res[0] - input_shape[0]\n",
    "        if crop=='lower right':\n",
    "            cx0, cy0 = new_res - input_shape        \n",
    "        cx0 = np.repeat(np.expand_dims(cx0, 0), len(info))\n",
    "        cy0 = np.repeat(np.expand_dims(cy0, 0), len(info))\n",
    "\n",
    "    cx1 = cx0 + input_shape[0]\n",
    "    cy1 = cy0 + input_shape[1]\n",
    "    \n",
    "    raw_imgs = load_images(info, input_shape=tuple(new_res))\n",
    "    \n",
    "    cropped_imgs = np.zeros((len(info), input_shape[0], input_shape[1], 3))\n",
    "    for ind in range(len(info)):\n",
    "        cropped_imgs[ind,:,:,:] = raw_imgs[ind,\n",
    "                                           cy0[ind]:cy1[ind],\n",
    "                                           cx0[ind]:cx1[ind], :]\n",
    "    \n",
    "    return cropped_imgs\n",
    "\n",
    "\n",
    "def get_image_gen(info_arg, \n",
    "                  shuffle=True, \n",
    "                  image_aug=True, \n",
    "                  eq_dist=False, \n",
    "                  n_ref_imgs=16, \n",
    "                  crop_prob=0.2, \n",
    "                  crop_p=0.3):\n",
    "    if image_aug:\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=4.,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.5,\n",
    "            channel_shift_range=25,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        \n",
    "        if crop_prob > 0:\n",
    "            datagen_crop = ImageDataGenerator(\n",
    "                rotation_range=4.,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.1,\n",
    "                channel_shift_range=20,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "        \n",
    "    count = len(info_arg)\n",
    "    \n",
    "    while True:\n",
    "        if eq_dist:\n",
    "            def sample(df):\n",
    "                return df.sample(min(n_ref_imgs, len(df)))\n",
    "            info = info_arg.groupby('landmark_id', group_keys=False).apply(sample)\n",
    "        else:\n",
    "            info = info_arg\n",
    "        print('Generate', len(info), 'for the next round.')\n",
    "        \n",
    "        #shuffle data\n",
    "        if shuffle and count >= len(info):\n",
    "            info = info.sample(frac=1)\n",
    "            count = 0\n",
    "            \n",
    "        # load images\n",
    "        for ind in range(0,len(info), batch_size):\n",
    "            count += batch_size\n",
    "\n",
    "            y = info['landmark_id'].values[ind:(ind+batch_size)]\n",
    "            \n",
    "            if np.random.rand() < crop_prob:\n",
    "                imgs = load_cropped_images(info.iloc[ind:(ind+batch_size)], \n",
    "                                           crop_p=crop_p*np.random.rand() + 0.01, \n",
    "                                           crop='random')\n",
    "                if image_aug:\n",
    "                    cflow = datagen_crop.flow(imgs, \n",
    "                                              y, \n",
    "                                              batch_size=imgs.shape[0], \n",
    "                                              shuffle=False)\n",
    "                    imgs, y = next(cflow)                    \n",
    "            else:\n",
    "                imgs = load_images(info.iloc[ind:(ind+batch_size)])\n",
    "                if image_aug:\n",
    "                    cflow = datagen.flow(imgs, \n",
    "                                       y, \n",
    "                                       batch_size=imgs.shape[0], \n",
    "                                       shuffle=False)\n",
    "                    imgs, y = next(cflow)             \n",
    "\n",
    "            imgs = preprocess_input(imgs)\n",
    "    \n",
    "            y_l = label_encoder.transform(y[y>=0.])        \n",
    "            y_oh = np.zeros((len(y), n_cat))\n",
    "            y_oh[y >= 0., :] = one_hot_encoder.transform(y_l.reshape(-1,1)).todense()\n",
    "                    \n",
    "            yield imgs, y_oh\n",
    "\n",
    "def get_custom_loss(rank_weight=1., epsilon=1.e-9):\n",
    "    def custom_loss(y_t, y_p):\n",
    "        losses = tf.reduce_sum(-y_t*tf.log(y_p+epsilon) - (1.-y_t)*tf.log(1.-y_p+epsilon), \n",
    "                               axis=-1)\n",
    "        \n",
    "        pred_idx = tf.argmax(y_p, axis=-1)\n",
    "        \n",
    "        mask = tf.one_hot(pred_idx, \n",
    "                          depth=y_p.shape[1], \n",
    "                          dtype=tf.bool, \n",
    "                          on_value=True, \n",
    "                          off_value=False)\n",
    "        pred_cat = tf.boolean_mask(y_p, mask)\n",
    "        y_t_cat = tf.boolean_mask(y_t, mask)\n",
    "        \n",
    "        n_pred = tf.shape(pred_cat)[0]\n",
    "        _, ranks = tf.nn.top_k(pred_cat, k=n_pred)\n",
    "        \n",
    "        ranks = tf.cast(n_pred-ranks, tf.float32)/tf.cast(n_pred, tf.float32)*rank_weight\n",
    "        rank_losses = ranks*(-y_t_cat*tf.log(pred_cat+epsilon)\n",
    "                             -(1.-y_t_cat)*tf.log(1.-pred_cat+epsilon))        \n",
    "        \n",
    "        return rank_losses + losses\n",
    "    return custom_loss\n",
    "\n",
    "def batch_GAP(y_t, y_p):\n",
    "    pred_cat = tf.argmax(y_p, axis=-1)    \n",
    "    y_t_cat = tf.argmax(y_t, axis=-1) * tf.cast(\n",
    "        tf.reduce_sum(y_t, axis=-1), tf.int64)\n",
    "    \n",
    "    n_pred = tf.shape(pred_cat)[0]\n",
    "    is_c = tf.cast(tf.equal(pred_cat, y_t_cat), tf.float32)\n",
    "\n",
    "    GAP = tf.reduce_mean(\n",
    "          tf.cumsum(is_c) * is_c / tf.cast(\n",
    "              tf.range(1, n_pred + 1), \n",
    "              dtype=tf.float32))\n",
    "    \n",
    "    return GAP\n",
    "\n",
    "def binary_crossentropy_n_cat(y_t, y_p):\n",
    "    return keras.metrics.binary_crossentropy(y_t, y_p) * n_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/preprocessing/image.py:440: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  image.ImageDataGenerator.__init__).args:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate 3927337 for the next round.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py:68: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78aa9267b8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_example, y_example = next(train_gen)\n",
    "plt.imshow(X_example[1,:,:,:]/2. + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 9\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)\n",
    "\n",
    "# hyper parameters for model\n",
    "nb_classes = 2  # number of classes\n",
    "based_model_last_block_layer_number = 126  # value is based on based model selected.\n",
    "img_width, img_height = 256, 256  # change based on the shape/structure of your images\n",
    "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 50  # number of iteration the algorithm gets trained.\n",
    "learn_rate = 1e-4  # sgd learning rate\n",
    "momentum = .9  # sgd momentum to avoid local minimum\n",
    "transformation_ratio = .05  # how aggressive will be the data augmentation/transformation\n",
    "\n",
    "\n",
    "\n",
    "def train(train_data_dir, validation_data_dir, model_path):\n",
    "    # Pre-Trained CNN Model using imagenet dataset for pre-trained weights\n",
    "    base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "    # Top Model Block\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "    # add your top layer block to your base model\n",
    "    model = Model(base_model.input, predictions)\n",
    "    print(model.summary())\n",
    "\n",
    "    # # let's visualize layer names and layer indices to see how many layers/blocks to re-train\n",
    "    # # uncomment when choosing based_model_last_block_layer\n",
    "    # for i, layer in enumerate(model.layers):\n",
    "    #     print(i, layer.name)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all layers of the based model that is already pre-trained.\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
    "    # To save augmentations un-comment save lines and add to your flow parameters.\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       rotation_range=transformation_ratio,\n",
    "                                       shear_range=transformation_ratio,\n",
    "                                       zoom_range=transformation_ratio,\n",
    "                                       cval=transformation_ratio,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    os.makedirs(os.path.join(os.path.abspath(train_data_dir), '../preview'), exist_ok=True)\n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "    # save_to_dir=os.path.join(os.path.abspath(train_data_dir), '../preview')\n",
    "    # save_prefix='aug',\n",
    "    # save_format='jpeg')\n",
    "    # use the above 3 commented lines if you want to save and look at how the data augmentations look like\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                                  target_size=(img_width, img_height),\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical')\n",
    "\n",
    "    model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
    "\n",
    "    top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
    "    callbacks_list = [\n",
    "        ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_acc', patience=5, verbose=0)\n",
    "    ]\n",
    "\n",
    "    # Train Simple CNN\n",
    "    model.fit_generator(train_generator,\n",
    "                        samples_per_epoch=train_generator.nb_sample,\n",
    "                        nb_epoch=nb_epoch / 5,\n",
    "                        validation_data=validation_generator,\n",
    "                        nb_val_samples=validation_generator.nb_sample,\n",
    "                        callbacks=callbacks_list)\n",
    "\n",
    "    # verbose\n",
    "    print(\"\\nStarting to Fine Tune Model\\n\")\n",
    "\n",
    "    # add the best weights from the train top model\n",
    "    # at this point we have the pre-train weights of the base model and the trained weight of the new/added top model\n",
    "    # we re-load model weights to ensure the best epoch is selected and not the last one.\n",
    "    model.load_weights(top_weights_path)\n",
    "\n",
    "    # based_model_last_block_layer_number points to the layer in your model you want to train.\n",
    "    # For example if you want to train the last block of a 19 layer VGG16 model this should be 15\n",
    "    # If you want to train the last Two blocks of an Inception model it should be 172\n",
    "    # layers before this number will used the pre-trained weights, layers above and including this number\n",
    "    # will be re-trained based on the new data.\n",
    "    for layer in model.layers[:based_model_last_block_layer_number]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[based_model_last_block_layer_number:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # save weights of best training epoch: monitor either val_loss or val_acc\n",
    "    final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n",
    "    callbacks_list = [\n",
    "        ModelCheckpoint(final_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "    ]\n",
    "\n",
    "    # fine-tune the model\n",
    "    model.fit_generator(train_generator,\n",
    "                        samples_per_epoch=train_generator.nb_sample,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=validation_generator,\n",
    "                        nb_val_samples=validation_generator.nb_sample,\n",
    "                        callbacks=callbacks_list)\n",
    "\n",
    "    # save model\n",
    "    model_json = model.to_json()\n",
    "    with open(os.path.join(os.path.abspath(model_path), 'model.json'), 'w') as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x_model = Xception(input_shape=list(input_shape) + [3], \n",
    "                   weights='imagenet', \n",
    "                   include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_8\n",
      "add_2\n",
      "add_1\n"
     ]
    }
   ],
   "source": [
    "print((x_model.layers[85]).name)\n",
    "print((x_model.layers[25]).name)\n",
    "print((x_model.layers[15]).name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 11,630,312\n",
      "Non-trainable params: 9,231,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in x_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "for layer in x_model.layers[:85]:\n",
    "    layer.trainable = False   \n",
    "    \n",
    "x_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 4, 4, 2048)   20861480    lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Concatena (None, 4, 4, 2048)   0           xception[1][0]                   \n",
      "                                                                 xception[2][0]                   \n",
      "                                                                 xception[3][0]                   \n",
      "                                                                 xception[4][0]                   \n",
      "                                                                 xception[5][0]                   \n",
      "                                                                 xception[6][0]                   \n",
      "                                                                 xception[7][0]                   \n",
      "                                                                 xception[8][0]                   \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 11,630,312\n",
      "Non-trainable params: 9,231,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multi_gpu_model(x_model,gpus=8)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (?, 4, 4, 2048) and (?, 4, 4, 4) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-176bb4f60bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model.compile(loss=loss, \n\u001b[1;32m      6\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               metrics=['accuracy'])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5e29e55163ae>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(y_t, y_p)\u001b[0m\n\u001b[1;32m    137\u001b[0m                           \u001b[0mon_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                           off_value=False)\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mpred_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0my_t_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mboolean_mask\u001b[0;34m(tensor, mask, name, axis)\u001b[0m\n\u001b[1;32m   1320\u001b[0m           \" are None.  E.g. shape=[None] is ok, but shape=None is not.\")\n\u001b[1;32m   1321\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m     \u001b[0mshape_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[0mleading_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \"\"\"\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?, 4, 4, 2048) and (?, 4, 4, 4) are incompatible"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "loss = get_custom_loss(1.0)\n",
    "#loss='categorical_crossentropy'\n",
    "#loss='binary_crossentropy'\n",
    "model.compile(loss=loss, \n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the following code is for GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gm_exp = tf.Variable(3., dtype=tf.float32)\n",
    "# def generalized_mean_pool_2d(X):\n",
    "#     pool = (tf.reduce_mean(tf.abs(X**(gm_exp)), \n",
    "#                            axis=[1,2], \n",
    "#                            keepdims=False)+1.e-8)**(1./gm_exp)\n",
    "#     return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_feat = Input(x_model.output_shape[1:])\n",
    "\n",
    "# lambda_layer = Lambda(generalized_mean_pool_2d)\n",
    "# lambda_layer.trainable_weights.extend([gm_exp])\n",
    "# X = lambda_layer(X_feat)\n",
    "# X = Dropout(0.05)(X)\n",
    "# X = Activation('relu')(X)\n",
    "# X = Dense(n_cat, activation='softmax')(X)\n",
    "\n",
    "# top_model = Model(inputs=X_feat, outputs=X)\n",
    "# top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_image = Input(list(input_shape) + [3])\n",
    "\n",
    "# X_f = x_model(X_image)\n",
    "# X_f = top_model(X_f)\n",
    "\n",
    "# model = Model(inputs=X_image, outputs=X_f)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(lr=0.0001)\n",
    "# loss = get_custom_loss(1.0)\n",
    "# #loss='categorical_crossentropy'\n",
    "# #loss='binary_crossentropy'\n",
    "# model.compile(loss=loss, \n",
    "#               optimizer=opt, \n",
    "#               metrics=[binary_crossentropy_n_cat, 'accuracy', batch_GAP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint1 = ModelCheckpoint('dd_checkpoint-1.h5', \n",
    "                              period=1, \n",
    "                              verbose=1, \n",
    "                              save_weights_only=True)\n",
    "checkpoint2 = ModelCheckpoint('dd_checkpoint-2.h5', \n",
    "                              period=1, \n",
    "                              verbose=1, \n",
    "                              save_weights_only=True)\n",
    "checkpoint3 = ModelCheckpoint('dd_checkpoint-3-best.h5', \n",
    "                              period=1, \n",
    "                              verbose=1, \n",
    "                              monitor='loss', \n",
    "                              save_best_only=True, \n",
    "                              save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.set_value(model.optimizer.lr, 0.0000003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/utils/data_utils.py:651: DeprecationWarning: `wait_time` is not used anymore.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py:68: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2048,203094] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/model_1/dense_1/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-dfbf8e3d570a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     callbacks=[checkpoint1, checkpoint2, checkpoint3])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,203094] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/model_1/dense_1/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen, \n",
    "                    steps_per_epoch=len(train) / batch_size / 8, \n",
    "                    epochs=50, \n",
    "                    callbacks=[checkpoint1, checkpoint2, checkpoint3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('dd_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
